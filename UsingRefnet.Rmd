---
title: "UsingRefnet"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r, warning=FALSE, message=FALSE}
library(devtools)
library(tidyverse)
library(stringr)
#devtools::install_github("embruna/refnet2", subdir = "refnet")  
library(refnet)
```


This reads in single files. Can specify a directory & set dir=TRUE flag to read in entire directory of files.
If the filename_root argument is not "" then it is used to create the root filenames for CSV output:

> EB: I have uploaded three sample datafiles: EBdata, Peru, Ecuador, ane Ecuador2 (downloaded jan 2017). They include one that was originally used by FS to test-drive refnet, one that got hung up because of the change by Thomson-Reuters in how they coded ResearcherID (Peru) and one downloaded from WOS on 11 jan 2016 that has the new ResearchID tag AND has the ORCID ID field code.

> Note that Thomson-Reuters adds ORCID ID all article records retroactively (i.e., even if person didn't have an ORCID ID at the time they had submitted the paper). This and the greater updtake of ORCID than other ID numbers makes it the best option for disambiguating author names.

> This uses some sample datasets posted to guthub Use package RCurl dowload them see: https://www.r-bloggers.com/data-on-github-the-easy-way-to-make-your-data-available/ 

The first argument of "read_references" should point to the folder where your data files are installed. 

> EMB: I have been using the following files to test drive the package: 
    - Ecuador.txt
    - Ecuador_0114.txt: Data from all 55 journals 2001-2014 downloaded 1/20/2017
    - EBpubs.txt: Emilio Bruna's articles (downloaded Jan 2017)
    - peru.txt
    - Ecology.txt: all articles published in Ecology in 2016

```{r ecuador1read}
eb_references <- read_references(data="~/refnet2/data/EBpubs.txt", 
                                 dir=FALSE, 
                                filename_root="./output/eb")

eb_authors <- read_authors(eb_references, 
                       filename_root="./output/eb")

eb_refined <- refine_authors(authors=eb_authors)


ecology_references <- read_references("./data/Ecology.txt", 
                                 dir=FALSE, 
                                 filename_root="./output/ecology")

output <- read_authors(ecology_references, 
                       filename_root="./output/ecology")

ecology_authors <- output$authors

ecology_authors_references <- output$authors_references

```

 
# NEXT STEPS (12 jan 2017)             
1) the researcherID is not being read in correctly due to T-R changing from RID to RI...

## FIX LIST
- Somewhere in going from FOO_references to FOO_authors it is failing to read in the addresses 
- in cells where there are multiple authros in the same institution
- The problem must be in read_authors(function) and how it divides the record to assign to C1
- EG for WOS:000282982300009
- Correctly assigns the address for Killen, TJ but leaves a blank address for Vasquez-Martinez 
- reads in [Killeen, TJ; Vasquez-Martinez, R] Conservat Int, Ctr Appl Biodivers Sci, Washington, DC USA. 
 
- Can try to include in the code for read_authors, but might be best to just hack and add to file later.


# Need to figure out how to get WOS record in there to match them all up./

```{r, eval=FALSE}
test<- eb_references %>% select (C1,UT)
names(test)[1]<-"foo"
foo<-full_join(foo,test,by="foo")
```

# BACK TO FORREST'S ORIGINAL INSTRUCTIONS

After reading the files in you can check the ecuador_authors.csv file and by hand in Excel, using the AU_ID_Dupe and Similarity fields, merge any author records that represent the same author.

After doing so you can read these back into R using the following, or if you're not starting from scratch above:

Can be read back in without importing from the following three commands:

##	Calculate the percentage of author records without contact information:


Let's remove duplicates from our presumably updated and corrected author lists:

```{r}
output <- remove_duplicates(authors=ecology_authors, 
                 authors_references=ecology_authors_references,
                   filename_root="output/ecology_nodupe")

ecology_authors <- output$authors
ecology_authors_references <- output$authors_references


output <- remove_duplicates(authors=eb_authors, 
                  authors_references=eb_authors_references,
                  filename_root="output/eb_nodupe")

eb_authors <- output$authors
eb_authors_references <- output$authors_references
```

Now let's merge references, authors, and authors__references:
```{r}
output <- merge_records(
	references=ecology_references, 
	authors=ecology_authors, 
	authors_references=ecology_authors_references, 

	references_merge=eb_references, 
	authors_merge=eb_authors, 
	authors_references_merge=eb_authors_references,
	
	filename_root = "output/merged"
)

save(output, file=paste0(Sys.Date(),"_merged_records_ecology_eb.Rdata"))

merged_references <- output$references
merged_authors <- output$authors
merged_authors_references <- output$authors_references

```

And finally after scrolling through and hand-correcting any authors from the merged list that have a high similarity:

```{r}
#merged_authors <- read.csv("./output/merged_authors.csv", as.is=TRUE)

output <- remove_duplicates(authors=merged_authors, 
                authors_references=merged_authors_references,
                filename_root="output/merged_nodupe")

merged_authors <- output$authors
merged_authors_references <- output$authors_references
```

Sample geographic plotting of author locations based on RP or C1:

How to process addresses:
```{r}
authors_working <- merged_authors
```

Process a single address at a time:


Sample using the first C1 address listed for the first 1000 authors, keyed by author so we can join it back:
NOTE:  The string "NA" does get translated to a point so we'll remove it before passing it along:

```{r}
address_list_working <- sapply(strsplit(authors_working$C1[1:1000], "\n"), FUN=function(x) { return(x[1]) })

address_list_working_au_id <- authors_working$AU_ID[1:1000][!is.na(address_list_working)]

address_list_working <- address_list_working[!is.na(address_list_working)]

##	Let's try to strip off any institutional references which may complicate geocoding:
address_list_working <- gsub("^.* (.*,.*,.*)$", 
                             "\\1",
                             address_list_working)

address_list_working <- gsub("[. ]*$", 
                             "", 
                             address_list_working)

```

Use the full list to create addresses from the C1 records:

```{r}
addressdf <- data.frame(
  "id"=address_list_working_au_id, 
  "type"="C1", 
  "address"=address_list_working, 
  stringsAsFactors=FALSE)

##	Use the full list to create addresses from the C1 records:
addresses_working <- read_addresses(x=addressdf, 
      filename_root="output/merged_nodupe_addresses_C1_first1000")
```

Now we can use those addresses to plot things out:
```{r}
plot_addresses_country(addresses_working)
plot_addresses_points(addresses_working)
```

Uncomment to save as a PDF, and display the semi-transparent edge color:

```{r}
#pdf("output/merged_nodupe_first1000_linkages_countries.pdf")
net_plot_coauthor(addresses_working, merged_authors_references)
#dev.off()
net_plot_coauthor_country(addresses_working, merged_authors_references)

```

The default plot area doesn't show semitransparent colors, so we'll output to PDF:

```{r}
output <- net_plot_coauthor_country(addresses_working, merged_authors_references)


ggsave("output/merged_nodupe_first1000_linkages_countries_world_ggplot.pdf", output, h = 9/2, w = 9)
```

We can subset records any way that makes sense.  For example, if we wanted to only use references from 2012 (note that the way records are read in they are strings and have a hard return character):

```{r}
##	We can subset records any way that makes sense.  For example, if we wanted to only use references from 2012 (note that the way records are read in they are strings and have a hard return character):
ref_index <- merged_references$PY == "2016\n"|merged_references$PY == "2016"
summary(ref_index)

##	Pull reference IDs (UT field) for just those from 2012:
UT_index <- merged_references$UT[ref_index]

merged_authors_references_subset <- merged_authors_references[ merged_authors_references$UT %in% UT_index, ]

##	Plot the subset for 2012:
net_plot_coauthor_country(addresses_working, merged_authors_references_subset)


```