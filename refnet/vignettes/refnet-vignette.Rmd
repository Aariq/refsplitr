---
title: "RefNet"
author: "Forest Stevens, Auriel Fournier, Matt Boone, Emilio Bruna (order of 1&2 TBD)"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{RefNet}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

##1 Introduction

Bibliometric databases, such as SCOPUS and the Web of Science, are a rich source of data for quantifying scientific productivity and studying factors shaping the emergence, disemination, and impact of research (Sugimoto and Larivière 2018). In recent years the type and scope of questions that researchers could address with these databases has expanded tremendously (Forutnato et al. 2018), in part because of their broader coverage, greater accessibility, and advances in computational power. Neverthtless, the ability to do so continues to be hampered - especially as the size of datasets increases - by two major and persistent challenges:

- 1 - Name disambiguation. Correctly identifying the authors of a research product is fundamental to bibliometric research, as is the ability to correctly attribute to an author all of their scholarly output. However, this seemingly simple task can often be extremely complicated (reviewed in Smalheiser and Torvik 2009), even when using the nominally high-quality data extracted from bibliometric databases. The most obvious case is when different authors have identical names, which in some countries is quite common (Strotmann et al. 2009). However, confusion might also arise as a result of journal conventions for reporting author names; for instance, one could erroneously conclude that there are two authors when there is only one (e.g., "JC Smith" and "Jennifer C Smith") or vice versa (e.g., "Enrique Gonzalez" and "Emilio Gonzalez" both abbrevaited as "E Gonzales"). Although failure to disambiguate author names can seriously undermine the conclusions of analyses,  verifying author identity manually quickly becomes impractical as the number of authors in a dataset increases. 

- 2 - Parsing author addresses. The structure of author affiliations is complex and idosyncratic, and journals differ in the information they require authors to provide as well as the way in which they present it. For instance, researchers at academic institutions might be associated with a Center, Institute, College, Department, or Programs.  These affiliations might be presented in different ways (e.g., Dept. of Biology vs. Department of Biology vs. Departamento de Biologia); the same is true of the institutions themselvees (UC Davis vs. University of California-Davis) and even the countries in which they are based (USA vs. United States of America). Furthermore, the same institution can have researchers working in different - often geographically disparate locations. 
Finally, all of this (highly variable) data is pooled under a single code of the reference record. In concert, these factors make analyses for which author institution or affiliation is of particular interest -- including spatially explict ones -- especially challenging.     

`refnet` is an R package designed to help users address these challenges. It imports and organizes the output from [Web of Science](https://login.webofknowledge.com/error/Error?PathInfo=%2F&Error=IPError) and [SCOPUS](https://www.scopus.com/home.uri) searches, disambiguates author names and flags any needing additional scrutiny, and parses author addresses to extract and georeference the institution at which they are based. Authors can also use it to generate simple summary bibliometric statistics and map author locations and coauthorships. Finally, authors can export the data in tidy formats for more in-dpeth analyses with their own code or packages such as 'revtools' (Westgate 2018a,b) or 'bibliometrix' (Aria & Cuccurullo 2017). 


## Using RefNet

Refnet's tools are applied in four steps: (1) data import and tidying, (2) disambiguation of author names, (3) parsing author addresses to extract and georeference author institutions, and (4) data analysis and visualization (Fig 1).  Each of these steps is described below.

<img src="flowchart.jpg" height="300" /> 
**Figure 1 - The Steps of _refnet_**

###Step 1 - Importing Search Results 

The `refnet` package can import a single Web of Science data file or import and combine multiple files saved in the same directory. The acceptable file formats are '.txt' and '.ciw'. For this step we will use the `read_references()` function, which has three arguments:  

- **data**: The directory location of the Web of Science file(s). If left blank it assumes the files are in the working directory. If in a different directory, the absolute file name or relative file paths can be used.  
- **dir**: This is TRUE when loading multiple files stored in a folder and FALSE when loading a single file.
- **filename_root**: This specifies the location in which the output - a csv file of processed references - is to be saved and the prefix used to name this file. If you do not want to write a file leave this field blank.

The output of `read_references()` is a file in which each line is a WOS record with its respective value for each WOS field tag. If the directory contained multiple WOS files, the files were merged and any duplictae records were removed. This resulting output file is used as a base for subsequent processing by `refnet`.

<img src="Reference.PNG" height="300" /> 

Examples: 

a) To import and process a single file located in a folder named "data" and save the output as a file named "Brazil" it in a folder named "output":

`read_references(data = './data/Brazil.txt', dir = F, filename_root = './output/Brazil')` 

b) To import and process multiple files located in a folder named "data" and save the output as "WOS" in a folder named "output":  

`read_references(data = './data', dir = T, filename_root = './output/WOS')`

c) To save to a location with a prefix, write the folder path followed by a '/' and then the prefix:  
`"./newpath/newprefix".`

This will save the file under the root directory as "/newpath/newprefix_references.csv". 


###Step 2 - Author Disambiguation

####Refnet Disambiguation Algorithm
The next step in the process is to use the newly made reference sheet to identify authors names and identify what authors are the same person. This can be difficult because different journals publish names in different formats. Sometimes with First names, sometimes only initials, sometimes with middle names, sometimes with no middle initial. It is because of this the function attempts to match names that are similar. However, these matches need to be hand checked for accuracy.

For this we'll use the `read_authors()` function. It takes the reference sheet we created and outputs a file of matched authors, and a master list. It has two arguments:  

- **references**: This is an object created from read_references. You can load in a previous reference sheet as long as it's an output from read_references and is saved to an object  
- **filename_root**: This is used to specify the location and prefix of the two objects. It works the exact same way as read_references. 


####Manual verification and correction of author names

Now that the algorithm has attempted to match similar names the user needs to hand check the matches. Open up the 'authors' output from the previous function. There are two important pieces of information in these files:  

- **AuthorID/GroupID**: There are two ID fields, AuthorID and GroupID. AuthorID is the unique identifier for each entry. GroupID is the ID that identifies what records are the same person.  

- **Match name**: This is the matching name the algorithm identified as part of the same author group.   

- **Similarity**: This is the similarity score calculated on likely matches. This is calculated using jaro-winkler similarity analysis. This is not performed on exact name matches or matches that did not have similar last name, first, middle combinations. This is a score from 1-100. 100 being an exact match.  

The algorithm attempts to match similar authors and then assigns similar authors to the same groupID. It then saves all match names into a file appended with '_authors.csv'. This file is the one you want to hand check matches, because it does it this iteratively the **groupID will always be the smallest authorID** of the group.

<img src="AuthorMatch.PNG" height="300" /> 

The sheet is ordered by groupID and then authorID. Go through each match and check that the matches make sense. You can use the similarity score, physical address, and email address to help assess whether names are the same or not. If in doubt, prior knowledge or Google should be helpful. If you find authors that are **NOT** the same person but assigned the same groupID, simply change each records **groupID** to its **authorID** to make them independent groups. 

Conversely, if you find authors that should be grouped (difficult to find), then you change each records **GroupID** to the same **GroupID** so that all records match. In this case it is good practice to make the groupID the smallest authorID of the cohort. 

When you're done, save this .csv file, load it back into R and we'll merge the change records in the next step.

####Uploading and merging corrections   

After making final assignments of similar authors, we want to merge the changes together for use in the final analysis. For this we'll use the `refine_authors()` function. It has four arguments:  
 
- **authors**: This is the new fixed authors object we saved previously. Must be in an object  
- **master**: This should be the unedited master file that was created from read_authors(). Must be in an object   
- **sim_score**: If you would like to set a threshold for the similarity score, where all scores below a threshold are assigned novel groupIDs, set the cut off here. By default this is turned off.  
- **filename_root**: The location and prefix of the output, works the same as the other functions.  

###Step 3 Identifying and georeferencing author institutions 

Now that we've identified matching authors we will calculate the authors location including their latitudes and longitudes for later mapping. We will use the `address_lat_long()` function. It has 2 arguments:  

- data: This is the output created from refine_authors. Must be an object.  
- address_column: This is a quoted character identifying what the column name that the addresses are stored in.  

The output is a modified data.frame with new columns for the latitude and longitude as well as various pieces of the address the algorithm could correctly parse out.  

> **warning** in the current version has trouble differentiating between separte campuses with similar names (e.g. University of Florida Main Campus, vs University of Florida Sattellite Campus). Depending on the resolution of your analysis this may be problematic, and we are working to address it **warning**

To create an output of the entries that `refnet2` was unable to georeference set the **write_out_missing** argument to **TRUE**. Then the user can fill in any they are able to determine and the newly populated address entries can be brought back into R. 

```
addresses <- address_lat_long(data)

new_address <- read.csv("missing_addresses.csv", 
                          stringsAsFactors = FALSE)

masteraddresses <- rbind(addresses$not_missing_addresses,
                          new_address)
```

> **warning** This function parses out addresses from the web of science reference sheet and then attempts to calculate the latitude and longitude using the datascience toolkit or Google maps API. This means it needs to use the internet and may take a rather long time to process depending on the amount of addresses it has to calculate. **warning**  

###Step 4 - Data Visualization

Now that we've successfully imported, cleaned, disambiguated and georeferenced the data. We can begin plotting the data. There five kinds of plots you can make. They are in two categories **World plots** and **Net Plots**. World plots simply plot author locations on a world map. Net plots use network analysis to plot connections of co-authorship on papers. We'll go from simple to complex. It's important to note that the rendering of these plots may take time, particularly if the amount of individual authors is >1000, depending on your computers processing power. So give it time if you are using an older computer or attempting to map a large number of points

####World Plots (by country)
To make a colored plot of all authors country of residency we'll use the `plot_addresses_country()`. The function has one argument:  

- **data**: This is the output from addresses_lat_long. Must be an object.

<img src="WorldCountry.png" height="300" /> 

####World Plots (points)
To individual plot points of each authors location we'll use the `plot_addresses_points()`. The function has one argument:  

- **data**: This is the output from `addresses_lat_long()`. Must be an object.

<img src="WorldPoint.png" height="300" /> 

####Net Plots (base)
To plot a network diagram of co-author countries of origins and how they're connected we'll use the `net_plot_coauthor()` function. The function has one argument:  

- **data**: This is the output from `addresses_lat_long()`. Must be an object.

This function has two outputs, in the form of a list. $plot is the plot, $data is the dataframe that was used to the build the plot. listname$plot is not very customizable, which is why $data is provided, so the user can build their own plot to their specific needs. 

<img src="NetPlotBase.png" height="300" /> 


####Net Plots (Country)
To plot a network diagram of co-author countries of origins overlayed on a world map we'll use **net_plot_coauthor_country()** function. The function has one argument:  

- **data**: This is the output from `addresses_lat_long()`. Must be an object.  

The net plot analysis returns an object that allows the plotting of these complex connections. `$plot` will plot the output to your plotting console. `$data` is the dataframe that was used to the build the plot. `$plot` is not very customizable, which is why `$data` is provided, so the user can build their own plot to their specific needs. 

<img src="NetPlotCountry.png" height="300" /> 


####Net Plots (Addresses)
To plot a network diagram of co-author using their individual addresses overlayed on a world map we'll use `net_plot_coauthor_addresses()` function. The function has one argument:  

- **data**: This is the output from addresses_lat_long. Must be an object.

The net plot analysis returns an object that allows the plotting of these complex connections. `$plot` will plot the output to your plotting console.  `$data` is the dataframe that was used to the build the plot. `$plot` is not very customizable, which is why $data is provided, so the user can build their own plot to their specific needs. 

This function can create a large data set (100's of MB), and may takes several minutes, so be patient and take the size of resources into account when running.  

<img src="NetPlotAddress.png" height="300" /> 



##Summary


##Acknowledgments

Support for the development of RefNet was provided by grants from the University of Florida's Center for Latin American Studies and Informatics Institute.

##References

Aria, M. & Cuccurullo, C. (2017) bibliometrix: An R-tool for comprehensive science mapping analysis, Journal of Informetrics,  11(4), pp 959-975, Elsevier.

Fortunato, S., C. T. Bergstrom, K. B?rner, J. A. Evans, D. Helbing, S. Milojevic, A. M. Petersen, F. Radicchi, R. Sinatra, B. Uzzi, A. Vespignani, L. Waltman, D. Wang, & A.-L. Barab?si. 2018. Science of science 359:eaao0185.

Smalheiser, N. R., & Torvik, V. I. (2009). Author name disambiguation. Annual review of information science and technology, 43(1), 1-43.

Strotmann, A. and Zhao, D., 2012. Author name disambiguation: What difference does it make in author‐based citation analysis?. Journal of the Association for Information Science and Technology, 63(9): 1820-1833.

Sugimoto CR, Larivière V. 2018. Measuring Research: What Everyone Needs to Know®. Oxford University Press, Oxford, UK. 149 pp.

Sci2 Team. (2009). Science of Science (Sci2) Tool. Indiana University and SciTech Strategies, https://sci2.cns.iu.edu. 

Westgate, M. J. (2018a). revtools: Tools to Support Evidence Synthesis. R package version 0.2.2.
  https://CRAN.R-project.org/package=revtools
  
Westgate, M. J. (2018b). revtools: bibliographic data visualization for evidence synthesis in R. bioRxiv:262881. doi: 10.1101/262881
